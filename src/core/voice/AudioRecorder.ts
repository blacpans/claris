import type { Readable } from 'node:stream';
import { endianness } from 'node:os';
import record from 'node-record-lpcm16';

interface AudioRecordProcess {
  stream(): Readable;
  stop(): void;
}

const IS_LITTLE_ENDIAN = endianness() === 'LE';

/**
 * ãƒã‚¤ã‚¯å…¥åŠ›ã‚’åˆ¶å¾¡ã™ã‚‹ã‚¯ãƒ©ã‚¹
 * `node-record-lpcm16` ã®ãƒ©ãƒƒãƒ‘ãƒ¼
 */
export class AudioRecorder {
  private recording: AudioRecordProcess | null = null;
  private stream: Readable | null = null;

  /**
   * éŒ²éŸ³ã‚’é–‹å§‹ã—ã€éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è¿”ã™
   * @param sampleRate ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 16000)
   * @returns éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ  (PCM 16bit Little Endian)
   */
  start(sampleRate = 16000): Readable {
    if (this.recording) {
      this.stop();
    }

    try {
      this.recording = record.record({
        sampleRate: sampleRate,
        threshold: 0, // ç„¡éŸ³ã‚«ãƒƒãƒˆãªã—
        verbose: false,
        recordProgram: 'rec', // 'sox' or 'rec'
        silence: '10.0', // é•·æ™‚é–“ã®ç„¡éŸ³ã§ã®ã¿åœæ­¢ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ï¼‰
      }) as unknown as AudioRecordProcess;

      this.stream = this.recording.stream();
      return this.stream as Readable;
    } catch (err) {
      console.error('âŒ Microphone Error:', err);
      throw err;
    }
  }

  /**
   * ç™ºè©±åŒºé–“ã‚’éŒ²éŸ³ã™ã‚‹ï¼ˆTurn-Basedç”¨ï¼‰
   * Node.jså´ã§éŸ³é‡(RMS)ã‚’è¨ˆç®—ã—ã€ç„¡éŸ³æ¤œå‡ºã‚’è¡Œã†
   */
  async recordUtterance(silenceSeconds = 2.0, sampleRate = 16000): Promise<Buffer> {
    if (this.recording) this.stop();

    return new Promise((resolve, reject) => {
      const chunks: Buffer[] = [];
      // RMSé–¾å€¤ (16bit integer range: -32768 to 32767)
      // 500ã ã¨æ„Ÿåº¦ãŒè‰¯ã™ãã‚‹ã®ã§ 1500 ã«ä¸Šã’ã‚‹
      const THRESHOLD = 1500;

      let isSpeaking = false;
      let silenceStart = 0;
      const silenceDurationMs = silenceSeconds * 1000;
      const recordingStart = Date.now();

      console.log(`ğŸ¤ Recording started (Manual VAD)... Threshold: ${THRESHOLD}`);

      try {
        this.recording = record.record({
          sampleRate: sampleRate,
          threshold: 0,
          verbose: false,
          recordProgram: 'rec',
        }) as unknown as AudioRecordProcess;

        const stream = this.recording.stream() as Readable;

        const checkSilence = (chunk: Buffer) => {
          let sumSquares = 0;
          const len = Math.floor(chunk.length / 2);

          // Fast path: System is Little Endian AND buffer is aligned
          if (IS_LITTLE_ENDIAN && chunk.byteOffset % 2 === 0) {
            const int16Data = new Int16Array(chunk.buffer, chunk.byteOffset, len);
            for (let i = 0; i < int16Data.length; i++) {
              const int = int16Data[i]!;
              sumSquares += int * int;
            }
          } else {
            // Slow(er) path: Use DataView (Handles Unaligned & Endianness)
            const dataView = new DataView(chunk.buffer, chunk.byteOffset, chunk.length);
            for (let i = 0; i < len; i++) {
              const int = dataView.getInt16(i * 2, true); // true = Little Endian
              sumSquares += int * int;
            }
          }

          const rms = Math.sqrt(sumSquares / len);
          return rms;
        };

        stream.on('data', (chunk: Buffer) => {
          const rms = checkSilence(chunk);

          // ãƒã‚¤ã‚ºãƒ‡ãƒãƒƒã‚°ç”¨ï¼ˆãŸã¾ã«å‡ºåŠ›ï¼‰
          // if (Math.random() < 0.05) console.log(`ğŸ¤ RMS: ${rms.toFixed(0)}`);

          // éŒ²éŸ³é–‹å§‹ç›´å¾Œ(500ms)ã®ãƒãƒƒãƒ—ãƒã‚¤ã‚ºåˆ¤å®šã‚’ç„¡è¦–ã™ã‚‹
          if (Date.now() - recordingStart < 500) {
            return;
          }

          if (rms > THRESHOLD) {
            if (!isSpeaking) {
              console.log(`ğŸ¤ Speech detected! (RMS: ${rms.toFixed(0)})`);
              isSpeaking = true;
            }
            silenceStart = 0; // Reset silence timer
          } else {
            if (isSpeaking) {
              if (silenceStart === 0) silenceStart = Date.now();

              const silenceElapsed = Date.now() - silenceStart;
              if (silenceElapsed > silenceDurationMs) {
                console.log('ğŸ¤ Silence detected. Stopping...');
                this.stop(); // This triggers 'end'
              }
            }
          }
          if (isSpeaking) {
            chunks.push(chunk);
          }
        });

        stream.on('error', (err: unknown) => {
          console.error('ğŸ¤ Recording Error:', err);
          reject(err);
        });

        stream.on('end', () => {
          console.log(`ğŸ¤ Recording ended. Sent ${chunks.length} chunks.`);
          this.recording = null;
          resolve(Buffer.concat(chunks));
        });
      } catch (err) {
        reject(err);
      }
    });
  }

  /**
   * éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹
   */
  stop() {
    if (this.recording) {
      this.recording.stop();
      this.recording = null;
      this.stream = null;
    }
  }
}
