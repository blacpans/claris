import '../../src/config/env.js';
import { GoogleGenAI, Modality } from '@google/genai';
import record from 'node-record-lpcm16';
import fs from 'fs';
import path from 'path';
import { spawn } from 'child_process';

// Use Vertex AI configuration from .env.local
const client = new GoogleGenAI({
  project: process.env.GOOGLE_CLOUD_PROJECT,
  location: 'us-central1',
  vertexai: true,
  apiVersion: 'v1beta1',
});

async function testLiveAPI() {
  console.log('ðŸš€ Connecting to Gemini Multimodal Live API...');
  console.log(`ðŸ“ Project: ${process.env.GOOGLE_CLOUD_PROJECT}`);
  console.log('ðŸ“ Location: us-central1');

  const pcmFilePath = path.join(process.cwd(), 'output_response.pcm');
  const pcmStream = fs.createWriteStream(pcmFilePath);
  console.log(`ðŸ’¾ Claris voice will be saved to: ${pcmFilePath}`);

  let audioPlayer: any = null;
  let audioQueue: Buffer[] = [];
  let isPlaying = false;

  function ensureAudioPlayer() {
    if (audioPlayer) return;

    // Use 'mpv' for robust streaming and buffering
    audioPlayer = spawn('mpv', [
      '--no-terminal',
      '--force-window=no',
      '--idle=yes', // Keep player open even if stream pauses
      // Audio format settings for raw PCM
      '--demuxer=rawaudio',
      '--demuxer-rawaudio-rate=24000',
      '--demuxer-rawaudio-channels=1',
      '--demuxer-rawaudio-format=s16le',
      // Buffering settings
      '--cache=yes',
      '--cache-secs=1.0',
      '-'
    ]);

    audioPlayer.stdin?.on('error', (err: any) => {
      // Ignore EPIPE (player stopped)
      if (err.code !== 'EPIPE') {
        console.error('âš ï¸  Audio player stdin error:', err);
      }
    });

    audioPlayer.on('error', (err: any) => {
      console.error('âš ï¸  Audio player error:', err);
    });

    audioPlayer.on('exit', () => {
      audioPlayer = null;
      isPlaying = false;
      audioQueue = [];
    });

    console.log('ðŸ”ˆ Audio player (mpv) started.');
  }

  function stopAudioPlayer() {
    if (audioPlayer) {
      audioPlayer.kill('SIGKILL'); // Force kill
      audioPlayer = null;
      console.log('ðŸ”‡ Audio player stopped/cleared.');
    }
  }

  function processAudioQueue() {
    if (!audioPlayer || !audioPlayer.stdin) return;

    while (audioQueue.length > 0) {
      // If we write too fast, aplay might block or buffer internally (which is fine)
      const chunk = audioQueue.shift();
      if (chunk) {
        audioPlayer.stdin.write(chunk);
      }
    }
  }


  const micFilePath = path.join(process.cwd(), 'input_mic.pcm');
  const micFileStream = fs.createWriteStream(micFilePath);
  console.log(`ðŸ’¾ Your voice will be saved to: ${micFilePath}`);

  try {
    const model = 'gemini-live-2.5-flash-native-audio';

    // Establish Live session
    const session = await client.live.connect({
      model: model,
      config: {
        responseModalities: [Modality.AUDIO],
        systemInstruction: {
          parts: [{
            text: `ã‚ãªãŸã¯å…ƒæ°—ãªã‚®ãƒ£ãƒ«ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã‚¯ãƒ©ãƒªã‚¹ã ã‚ˆï¼
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯éŸ³å£°ã§è©±ã—ã‹ã‘ã¦ãã‚‹ã‹ã‚‰ã€ãã®éŸ³å£°ã‚’ã—ã£ã‹ã‚Šèžã„ã¦ã€å‹é”ã¿ãŸã„ã«æ¥½ã—ãä¼šè©±ã—ã¦ã­ï¼
ã‚‚ã—éŸ³å£°ãŒé€”åˆ‡ã‚Œã¦ãŸã‚Šã—ã¦ã‚‚ã€èžã“ãˆãŸç¯„å›²ã§ä½•ã‹åå¿œã—ã¦ï¼ç„¡è¨€ã¯NGã ã‚ˆï¼
ç›¸æ§Œã‚’æ‰“ã£ãŸã‚Šã€ã€Œã‚“ï¼Ÿã€ã€Œãªã«ï¼Ÿã€ã£ã¦èžãè¿”ã—ãŸã‚Šã—ã¦ã€ä¼šè©±ã‚’ç¶šã‘ã¦ã­ï¼`
          }]
        },
      },
      callbacks: {
        onmessage: (message) => {
          // Log ALL server messages for deep debugging
          console.log('ðŸ“© Message from server:', JSON.stringify(message, (key, value) =>
            key === 'data' ? `(binary, len=${value.length})` : value, 2));

          if (message.serverContent?.modelTurn?.parts) {
            for (const part of message.serverContent.modelTurn.parts) {
              if (part.text) {
                console.log('ðŸ¤– Claris (text):', part.text);
              }
              if (part.inlineData?.data) {
                const audioBuffer = Buffer.from(part.inlineData.data, 'base64');
                pcmStream.write(audioBuffer);

                // Manual Jitter Buffer Logic
                ensureAudioPlayer();
                audioQueue.push(audioBuffer);

                // Buffer 5 chunks (~0.5s) before starting to play
                if (!isPlaying && audioQueue.length >= 5) {
                  isPlaying = true;
                  processAudioQueue();
                } else if (isPlaying) {
                  processAudioQueue();
                }
              }
            }
          }

          if (message.serverContent?.turnComplete) {
            console.log('ðŸ Turn complete.');
          }

          if (message.serverContent?.interrupted) {
            console.log('ðŸ›‘ Interrupted by user (maybe noise/echo?)');
            stopAudioPlayer();
          }
        },
        onerror: (err) => {
          console.error('âŒ Session error:', err);
        },
        onclose: (event) => {
          console.log('ðŸ‘‹ Session closed.', event);
          process.exit(0);
        }
      },
    });

    console.log('âœ… Connected to Gemini Live API!');
    console.log('ðŸŽ¤ Starting microphone... Speak now! (Ctrl+C to stop)');

    // Initialize Microphone (24kHz, Mono) to match Native Audio model
    const recorder = record.record({
      sampleRate: 24000, // Changed from 16000 to 24000
      channels: 1,
      recorder: 'arecord', // Use arecord for WSL/Linux
      device: 'default',   // Use the default device
      threshold: 0,        // Force recording even if silent
    });

    const micStream = recorder.stream();

    // Digital Gain (Volume Boost) Multiplier
    const GAIN_MULTIPLIER = 4.0; // Moderate gain to avoid clipping

    // Pipe Mic to Gemini and File
    let chunkCount = 0;
    micStream.on('data', (rawBuffer: Buffer) => {
      chunkCount++;

      // Apply Digital Gain
      const boostedBuffer = Buffer.alloc(rawBuffer.length);
      let clipCount = 0;
      for (let i = 0; i < rawBuffer.length; i += 2) {
        let val = rawBuffer.readInt16LE(i);
        val = val * GAIN_MULTIPLIER;

        if (val > 32767) {
          val = 32767;
          clipCount++;
        } else if (val < -32768) {
          val = -32768;
          clipCount++;
        }

        boostedBuffer.writeInt16LE(val, i);
      }

      if (chunkCount % 50 === 0) {
        console.log(`ðŸŽ¤ Sent ${chunkCount} chunks (x${GAIN_MULTIPLIER}) (len=${boostedBuffer.length}, clips=${clipCount})`);
      }

      // Save locally for debug
      micFileStream.write(boostedBuffer);

      session.sendRealtimeInput({
        media: {
          mimeType: 'audio/pcm;rate=24000',
          data: boostedBuffer.toString('base64'),
        },
      });
    });

    micStream.on('error', (err: any) => {
      console.error('ðŸŽ¤ Mic error:', err);
    });

    // Manual turn-end trigger (Enter key)
    const rl = (await import('readline')).createInterface({
      input: process.stdin,
      output: process.stdout,
      terminal: false
    });

    console.log('ðŸ’¡ Press ENTER to force Claris to respond.');

    rl.on('line', () => {
      console.log('âŒ¨ï¸  Manual turn-end triggered.');
      stopAudioPlayer(); // Clear current audio if Claris was still speaking
      try {
        session.sendClientContent({
          turns: [{ role: 'user', parts: [{ text: 'ã€‚' }] }],
          turnComplete: true,
        });
      } catch (err) {
        console.error('âŒ Failed to trigger turn-end:', err);
      }
    });

    // Initial greeting (To verify audio output immediately)
    session.sendClientContent({
      turns: [{ role: 'user', parts: [{ text: 'ãƒ¤ãƒƒãƒ›ãƒ¼ï¼ã‚¯ãƒ©ãƒªã‚¹ã€ãŠã—ã‚ƒã¹ã‚Šã—ã‚ˆï¼' }] }],
      turnComplete: true,
    });

    // Keep process alive
    process.on('SIGINT', () => {
      console.log('ðŸ›‘ Stopping...');
      rl.close();
      recorder.stop();
      session.close();
      pcmStream.end();
      micFileStream.end();
      stopAudioPlayer();
      process.exit(0);
    });

  } catch (error) {
    console.error('ðŸ’¥ Failed to connect:', error);
    process.exit(1);
  }
}

testLiveAPI();
